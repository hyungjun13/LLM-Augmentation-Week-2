{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll build a basic LangChain agent. We'll leverage OpenAI for LLM responses and implement various tools to create a flexible, dynamic workflow. LangChain's agent framework will allow us to orchestrate different functions and API calls seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import os\n",
    "from rag import RagEngine \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Decorator Approach\n",
    "\n",
    "The `@tool` decorator in LangChain is used to easily register functions as tools that agents can use. It simplifies integration by marking the function for use in LangChain workflows without needing extra configuration.\n",
    "\n",
    "In this case, the `@tool` decorator:\n",
    "- Registers the `calculator` function as a callable tool for agents.\n",
    "- Allows the agent to evaluate mathematical expressions safely by using `eval()` with restricted input handling.\n",
    "\n",
    "This approach makes it easy to add modular, reusable tools to LangChain agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def calc(input_expr: str) -> int:\n",
    "    \"\"\"A simple calculator tool that evaluates a mathemtical expression and returns the result as an integer. Do not pass untrusted input.\"\"\"\n",
    "    return eval(input_expr.replace(\"^\", \"**\"), {}, {})\n",
    "\n",
    "tools = [calc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the expression (4.5*2.1)^2.2\n",
      "Action: calc\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 139.94\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Tools for the Agent\n",
    "\n",
    "In this section, we define two tools that the agent will use:\n",
    "\n",
    "1. **QA Chat Tool**: A simple question-answering tool that takes a user message and generates a response using a large language model (LLM).\n",
    "2. **RAG Chat Tool**: A more complex tool that handles document retrieval using Retrieval-Augmented Generation (RAG). This tool is specifically designed to retrieve and generate responses from environmental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the QA Chat Tool\n",
    "# This tool handles normal question-answering interactions by invoking the LLM\n",
    "@tool\n",
    "def qa_chat_tool(message: str) -> str:\n",
    "    \"\"\"Tool for handling normal question-answer (QA) interactions.\"\"\"\n",
    "\n",
    "    template = \"\"\"Respond to the user message:\n",
    "        message: {message}\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke(message)\n",
    "    return response # Return the generated response\n",
    "\n",
    "# Define the RAG Chat Tool: Feel free to change the rag document and description to add a different document\n",
    "# This tool handles document retrieval and generation using RAG from environmental data\n",
    "@tool\n",
    "def rag_chat_tool(message: str) -> str:\n",
    "    \"\"\"Tool for handling document retrieval and generating responses using RAG from environmental data.\"\"\"\n",
    "    \n",
    "    # Initialize the Retrieval-Augmented Generation (RAG) engine\n",
    "    rag_engine = RagEngine()\n",
    "    \n",
    "    # Use the RAG engine to return an answer to the user's query\n",
    "    response = rag_engine.return_answer(message)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling Application with Tools in LangChain\n",
    "\n",
    "In this example, we are creating a function-calling agent using LangChain. The agent is set up with tools such as `qa_chat_tool` and `rag_chat_tool`, which can be used for question-answering and retrieval-augmented generation tasks. The agent is initialized as a zero-shot agent, meaning it can take actions based on descriptions of the tools provided to it without requiring training on specific tasks.\n",
    "\n",
    "The `max_iterations` parameter limits the number of decision-making steps the agent can take before completing a task. Here's how to set up and initialize the agent with tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools the agent will use\n",
    "tools = [qa_chat_tool, rag_chat_tool]\n",
    "\n",
    "# Initialize the zero-shot agent\n",
    "# The agent is based on the \"zero-shot-react-description\" model, meaning it uses \n",
    "# reasoning and action descriptions to perform tasks without explicit training\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",  # Agent type for reasoning and decision making\n",
    "    tools=tools,  # List of tools the agent will have access to\n",
    "    llm=llm,  # The large language model (LLM) that powers the agent\n",
    "    verbose=True,  # Set to True to see detailed output of the agent's decision-making process\n",
    "    max_iterations=3  # Limit the agent to 3 iterations when performing actions\n",
    ")\n",
    "\n",
    "# You can now use zero_shot_agent to run function calls based on input queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the RAG chat tool to retrieve information on the cause of global warming.\n",
      "Action: rag_chat_tool\n",
      "Action Input: \"What is the cause of global warming?\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimh2/Documents/Uni/MDST/LLM-Augmentation-Week-2/rag.py:29: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  self.chunks, embedding=OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe cause of global warming is believed to be an enhanced greenhouse effect, with a marked increase in energy consumption leading to a rise in atmospheric carbon dioxide concentration.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should provide this information to answer the question.\n",
      "Action: qa_chat_tool\n",
      "Action Input: \"The cause of global warming is believed to be an enhanced greenhouse effect, with a marked increase in energy consumption leading to a rise in atmospheric carbon dioxide concentration.\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mYes, that is correct. The enhanced greenhouse effect is primarily caused by human activities such as burning fossil fuels, deforestation, and industrial processes, which release large amounts of greenhouse gases like carbon dioxide into the atmosphere. This leads to an increase in the Earth's temperature, resulting in global warming and its associated impacts on the environment and climate. It is important for us to reduce our energy consumption and transition to more sustainable and renewable sources of energy to mitigate the effects of global warming.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The cause of global warming is primarily attributed to an enhanced greenhouse effect, driven by human activities such as burning fossil fuels, deforestation, and industrial processes that release greenhouse gases into the atmosphere.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the cause of global warming?',\n",
       " 'output': 'The cause of global warming is primarily attributed to an enhanced greenhouse effect, driven by human activities such as burning fossil fuels, deforestation, and industrial processes that release greenhouse gases into the atmosphere.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This one may take a while oops\n",
    "zero_shot_agent(\"what is the cause of global warming?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the QA tool to get a straightforward answer to this question.\n",
      "Action: qa_chat_tool\n",
      "Action Input: \"What type of food is an apple?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAn apple is a type of fruit.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the answer to the question.\n",
      "Final Answer: An apple is a type of fruit.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What type of food is an apple?',\n",
       " 'output': 'An apple is a type of fruit.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"What type of food is an apple?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Your Turn\n",
    "\n",
    "Now, create a function-calling application of your own. You are encouraged to use external APIs to create robust tools. Feel free to change the rag engine to a more personalized document. You will may need to change rag.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the websiteRec tool to find suitable websites for learning Python.\n",
      "Action: websiteRec\n",
      "Action Input: \"learn Python\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI recommend checking out the website \"https://www.learnpython.org/\" for learning Python. It offers interactive tutorials and exercises to help you get started with Python programming.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThis website seems like a good resource for learning Python.\n",
      "Final Answer: The best website for learning Python is https://www.learnpython.org/.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the best website for learning Python?',\n",
       " 'output': 'The best website for learning Python is https://www.learnpython.org/.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool\n",
    "def websiteRec(message: str) -> str:\n",
    "    \"\"\"Tool for finding suitable websites for the prompt.\"\"\"\n",
    "\n",
    "    template = \"\"\"Respond to the user message with a website recommendation:\n",
    "        message: {message}\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke(message)\n",
    "    return response # Return the generated response\n",
    "\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",  # Agent type for reasoning and decision making\n",
    "    tools=[websiteRec],  # List of tools the agent will have access to\n",
    "    llm=llm,  # The large language model (LLM) that powers the agent\n",
    "    verbose=True,  # Set to True to see detailed output of the agent's decision-making process\n",
    "    max_iterations=3  # Limit the agent to 3 iterations when performing actions\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the websiteRec tool to find suitable websites for learning Python.\n",
      "Action: websiteRec\n",
      "Action Input: \"learn Python\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI recommend checking out the website \"https://www.codecademy.com/learn/learn-python\" for learning Python. It offers interactive lessons and projects to help you master the language.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThis website seems like a good option for learning Python.\n",
      "Final Answer: The best website for learning Python is https://www.codecademy.com/learn/learn-python.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the websiteRec tool to find suitable websites for my EECS270 project.\n",
      "Action: websiteRec\n",
      "Action Input: EECS270 project information\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI recommend checking out the official website for EECS270 at your university for project information. You can also visit the course page on the university's website for more details.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should also look for online forums or resources related to EECS270 projects.\n",
      "Action: websiteRec\n",
      "Action Input: EECS270 project forums\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI recommend checking out the EECS270 project forums on the university's website for information and discussions related to the course project. You can find helpful resources and connect with other students working on the same project.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should also search for academic journals or research papers related to topics in EECS270 for my project.\n",
      "Action: websiteRec\n",
      "Action Input: EECS270 research papers\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mI recommend checking out the IEEE Xplore website for a wide range of research papers related to EECS270. You can find a variety of papers on topics such as electrical engineering, computer science, and more. Here is the link: https://ieeexplore.ieee.org/\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Where should I find information for my EECS270 project',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"What is the best website for learning Python?\")\n",
    "\n",
    "zero_shot_agent(\"Where should I find information for my EECS270 project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
