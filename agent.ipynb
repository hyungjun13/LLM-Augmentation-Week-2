{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll build a basic LangChain agent. We'll leverage OpenAI for LLM responses and implement various tools to create a flexible, dynamic workflow. LangChain's agent framework will allow us to orchestrate different functions and API calls seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import os\n",
    "from rag import RagEngine \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/61/42wnfj3s4tg5231cbgvtmrnc0000gn/T/ipykernel_28903/2604697549.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Decorator Approach\n",
    "\n",
    "The `@tool` decorator in LangChain is used to easily register functions as tools that agents can use. It simplifies integration by marking the function for use in LangChain workflows without needing extra configuration.\n",
    "\n",
    "In this case, the `@tool` decorator:\n",
    "- Registers the `calculator` function as a callable tool for agents.\n",
    "- Allows the agent to evaluate mathematical expressions safely by using `eval()` with restricted input handling.\n",
    "\n",
    "This approach makes it easy to add modular, reusable tools to LangChain agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculator(input_expr: str) -> int:\n",
    "    \"\"\"A simple calculator tool that evaluates a mathemtical expression and returns the result as an integer. Do not pass untrusted input.\"\"\"\n",
    "    return eval(input_expr.replace(\"^\", \"**\"), {}, {})\n",
    "\n",
    "tools = [calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/61/42wnfj3s4tg5231cbgvtmrnc0000gn/T/ipykernel_28903/823011281.py:3: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  zero_shot_agent = initialize_agent(\n",
      "/var/folders/61/42wnfj3s4tg5231cbgvtmrnc0000gn/T/ipykernel_28903/823011281.py:11: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  zero_shot_agent(\"what is (4.5*2.1)^2.2?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the calculator tool to evaluate this mathematical expression.\n",
      "Action: calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 139.94\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Tools for the Agent\n",
    "\n",
    "In this section, we define two tools that the agent will use:\n",
    "\n",
    "1. **QA Chat Tool**: A simple question-answering tool that takes a user message and generates a response using a large language model (LLM).\n",
    "2. **RAG Chat Tool**: A more complex tool that handles document retrieval using Retrieval-Augmented Generation (RAG). This tool is specifically designed to retrieve and generate responses from environmental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the QA Chat Tool\n",
    "# This tool handles normal question-answering interactions by invoking the LLM\n",
    "@tool\n",
    "def qa_chat_tool(message: str) -> str:\n",
    "    \"\"\"Tool for handling normal question-answer (QA) interactions.\"\"\"\n",
    "\n",
    "    template = \"\"\"Respond to the user message:\n",
    "        message: {message}\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke(message)\n",
    "    return response['output']  # Return the generated response\n",
    "\n",
    "# Define the RAG Chat Tool\n",
    "# This tool handles document retrieval and generation using RAG from environmental data\n",
    "@tool\n",
    "def rag_chat_tool(message: str) -> str:\n",
    "    \"\"\"Tool for handling document retrieval and generating responses using RAG from environmental data.\"\"\"\n",
    "    \n",
    "    # Initialize the Retrieval-Augmented Generation (RAG) engine\n",
    "    rag_engine = RagEngine()\n",
    "    \n",
    "    # Use the RAG engine to return an answer to the user's query\n",
    "    response = rag_engine.return_answer(message)\n",
    "    return response['output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling Application with Tools in LangChain\n",
    "\n",
    "In this example, we are creating a function-calling agent using LangChain. The agent is set up with tools such as `qa_chat_tool` and `rag_chat_tool`, which can be used for question-answering and retrieval-augmented generation tasks. The agent is initialized as a zero-shot agent, meaning it can take actions based on descriptions of the tools provided to it without requiring training on specific tasks.\n",
    "\n",
    "The `max_iterations` parameter limits the number of decision-making steps the agent can take before completing a task. Here's how to set up and initialize the agent with tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools the agent will use\n",
    "tools = [qa_chat_tool, rag_chat_tool]\n",
    "\n",
    "# Initialize the zero-shot agent\n",
    "# The agent is based on the \"zero-shot-react-description\" model, meaning it uses \n",
    "# reasoning and action descriptions to perform tasks without explicit training\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",  # Agent type for reasoning and decision making\n",
    "    tools=tools,  # List of tools the agent will have access to\n",
    "    llm=llm,  # The large language model (LLM) that powers the agent\n",
    "    verbose=True,  # Set to True to see detailed output of the agent's decision-making process\n",
    "    max_iterations=3  # Limit the agent to 3 iterations when performing actions\n",
    ")\n",
    "\n",
    "# You can now use zero_shot_agent to run function calls based on input queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the RAG chat tool to retrieve information on the cause of global warming.\n",
      "Action: rag_chat_tool\n",
      "Action Input: \"What is the cause of global warming?\"\u001b[0m"
     ]
    }
   ],
   "source": [
    "#This one may take a while oops\n",
    "zero_shot_agent(\"what is the cause of global warming?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the QA tool to get a straightforward answer to this question.\n",
      "Action: qa_chat_tool\n",
      "Action Input: \"What type of food is an apple?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAn apple is a type of fruit. It is a sweet and crunchy fruit that is commonly eaten as a snack or used in various recipes.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the answer to the question about the type of food an apple is.\n",
      "Final Answer: An apple is a type of fruit.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What type of food is an apple?',\n",
       " 'output': 'An apple is a type of fruit.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"What type of food is an apple?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Your Turn\n",
    "\n",
    "Now, create a function-calling application of your own. You are encouraged to use external APIs to create robust tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def MyTool(___):\n",
    "    \"A description of the tool\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
